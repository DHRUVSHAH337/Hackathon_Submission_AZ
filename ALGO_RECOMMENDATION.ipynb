{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FOR TRAINING THE DATA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"  \")\n# Enter the path of the file","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data  =data.drop('timestamp',axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from surprise import SVD\nimport numpy as np\nimport surprise\nfrom surprise import Reader, Dataset\n\n# It is to specify how to read the data frame.\nreader = Reader(rating_scale=(1,5))\n\n# create the traindata from the data frame\ntrain_data_mf = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], reader)\n# build the train set from traindata. \n#It is of dataset format from surprise library\n\ntrainset = train_data_mf.build_full_trainset()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\nsvd.fit(trainset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting predictions of train set\ntrain_preds = svd.test(trainset.build_testset())\n\ntrain_pred_mf = np.array([pred.est for pred in train_preds])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\n\n# Creating a sparse matrix\ntrain_sparse_matrix = csr_matrix((train_data.rating.values, (train_data.userId.values,\n                                               train_data.movieId.values)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Global avg of all movies by all users\n\ntrain_averages = dict()\n# get the global average of ratings in our train set.\ntrain_global_average = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\ntrain_averages['global'] = train_global_average\n# train_averages","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the user averages in dictionary (key: user_id/movie_id, value: avg rating)\n\ndef get_average_ratings(sparse_matrix, of_users):\n    \n    # average ratings of user/axes\n    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n\n    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n    # Boolean matrix of ratings ( whether a user rated that movie or not)\n    is_rated = sparse_matrix!=0\n    # no of ratings that each user OR movie..\n    no_of_ratings = is_rated.sum(axis=ax).A1\n    \n    # max_user  and max_movie ids in sparse matrix \n    u,m = sparse_matrix.shape\n    # creae a dictonary of users and their average ratigns..\n    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n                                 for i in range(u if of_users else m) \n                                    if no_of_ratings[i] !=0}\n\n    # return that dictionary of average ratings\n    return average_ratings","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average ratings given by a user\n\ntrain_averages['user'] = get_average_ratings(train_sparse_matrix, of_users=True)\n# print('\\nAverage rating of user 10 :',train_averages['user'][10])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average ratings given for a movie\n\ntrain_averages['movie'] =  get_average_ratings(train_sparse_matrix, of_users=False)\n# print('\\n AVerage rating of movie 15 :',train_averages['movie'][15])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.sparse import find\n\n# get users, movies and ratings from our samples train sparse matrix\ntrain_users, train_movies, train_ratings = find(train_sparse_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\nfinal_data = pd.DataFrame()\ncount = 0\nfor (user, movie, rating)  in zip(train_users, train_movies, train_ratings):\n#             st = datetime.now()\n        #     print(user, movie)    \n            #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n            # compute the similar Users of the \"user\"        \n            user_sim = cosine_similarity(train_sparse_matrix[user], train_sparse_matrix).ravel()\n            top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar users for this movie\n            top_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n            # we will make it's length \"5\" by adding movie averages to .\n            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_users_ratings.extend([train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n        #     print(top_sim_users_ratings, end=\" \")    \n\n\n            #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n            # compute the similar movies of the \"movie\"        \n            movie_sim = cosine_similarity(train_sparse_matrix[:,movie].T, train_sparse_matrix.T).ravel()\n            top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar movie rated by this user..\n            top_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n            # we will make it's length \"5\" by adding user averages to.\n            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_movies_ratings.extend([train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n        #     print(top_sim_movies_ratings, end=\" : -- \")\n\n            #-----------------prepare the row to be stores in a file-----------------#\n            row = list()\n            row.append(user)\n            row.append(movie)\n            # Now add the other features to this data...\n            row.append(train_averages['global']) # first feature\n            # next 5 features are similar_users \"movie\" ratings\n            row.extend(top_sim_users_ratings)\n            # next 5 features are \"user\" ratings for similar_movies\n            row.extend(top_sim_movies_ratings)\n            # Avg_user rating\n            row.append(train_averages['user'][user])\n            # Avg_movie rating\n            row.append(train_averages['movie'][movie])\n\n            # finalley, The actual Rating of this user-movie pair...\n            row.append(rating)\n            count = count + 1\n            final_data = final_data.append([row])\n#             print(count)\n\n           \n        \n#             if (count)%10000 == 0:\n#                 # print(','.join(map(str, row)))\n#                 print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data.columns=['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n            'smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data['mf_svd'] = train_pred_mf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating XGBoost","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_error_metrics(y_true, y_pred):\n    rmse = np.sqrt(np.mean([ (y_true[i] - y_pred[i])**2 for i in range(len(y_pred)) ]))\n    mape = np.mean(np.abs( (y_true - y_pred)/y_true )) * 100\n    return rmse, mape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare train data\nx_train = final_data.drop(['user', 'movie','rating'], axis=1)\ny_train = final_data['rating']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\n# initialize XGBoost model...\nxgb_model = xgb.XGBRegressor(silent=False, n_jobs=13, random_state=15, n_estimators=100)\n# dictionaries for storing train and test results\ntrain_results = dict()\ntest_results = dict()\n    \n    \n# fit the model\n# print('Training the model..')\n# start =datetime.now()\nxgb_model.fit(x_train, y_train, eval_metric = 'rmse')\n# print('Done. Time taken : {}\\n'.format(datetime.now()-start))\n# print('Done \\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = pd.read_csv(\" \")\n# The link for test data set","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data=data1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It is to specify how to read the dataframe.\n# for our dataframe, we don't have to specify anything extra..\nreader = Reader(rating_scale=(1,5))\n\n# create the traindata from the dataframe...\ntest_data_mf = Dataset.load_from_df(test_data[['userId', 'movieId', 'rating']], reader)\n\n# build the trainset from traindata.., It is of dataset format from surprise library..\ntestset = test_data_mf.build_full_trainset()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting predictions of trainset\ntest_preds = svd.test(testset.build_testset())\n\ntest_pred_mf = np.array([pred.est for pred in test_preds])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a sparse matrix\nfrom scipy.sparse import csr_matrix\n\ntest_sparse_matrix = csr_matrix((test_data.rating.values, (test_data.userId.values,\n                                               test_data.movieId.values)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Global avg of all movies by all users\n\ntest_averages = dict()\n# get the global average of ratings in our train set.\ntest_global_average = test_sparse_matrix.sum()/test_sparse_matrix.count_nonzero()\ntest_averages['global'] = test_global_average\n# test_averages","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the user averages in dictionary (key: user_id/movie_id, value: avg rating)\n\ndef get_average_ratings(sparse_matrix, of_users):\n    \n    # average ratings of user/axes\n    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n\n    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n    # Boolean matrix of ratings ( whether a user rated that movie or not)\n    is_rated = sparse_matrix!=0\n    # no of ratings that each user OR movie..\n    no_of_ratings = is_rated.sum(axis=ax).A1\n    \n    # max_user  and max_movie ids in sparse matrix \n    u,m = sparse_matrix.shape\n    # creae a dictonary of users and their average ratigns..\n    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n                                 for i in range(u if of_users else m) \n                                    if no_of_ratings[i] !=0}\n\n    # return that dictionary of average ratings\n    return average_ratings","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average ratings given by a user\n\ntest_averages['user'] = get_average_ratings(test_sparse_matrix, of_users=True)\n#print('\\nAverage rating of user 10 :',test_averages['user'][10])\n\n# Average ratings given for a movie\n\ntest_averages['movie'] =  get_average_ratings(test_sparse_matrix, of_users=False)\n# print('\\n AVerage rating of movie 15 :',test_averages['movie'][15])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get users, movies and ratings from our samples train sparse matrix\nfrom scipy.sparse import find\n\ntest_users, test_movies, test_ratings = find(test_sparse_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_data = pd.DataFrame()\ncount = 0\nfor (user, movie, rating)  in zip(test_users, test_movies, test_ratings):\n#             st = datetime.now()\n        #     print(user, movie)    \n            #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n            # compute the similar Users of the \"user\"        \n            user_sim = cosine_similarity(test_sparse_matrix[user], test_sparse_matrix).ravel()\n            top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar users for this movie\n            top_ratings = test_sparse_matrix[top_sim_users, movie].toarray().ravel()\n            # we will make it's length \"5\" by adding movie averages to .\n            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_users_ratings.extend([test_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n        #     print(top_sim_users_ratings, end=\" \")    \n\n\n            #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n            # compute the similar movies of the \"movie\"        \n            movie_sim = cosine_similarity(test_sparse_matrix[:,movie].T, test_sparse_matrix.T).ravel()\n            top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar movie rated by this user..\n            top_ratings = test_sparse_matrix[user, top_sim_movies].toarray().ravel()\n            # we will make it's length \"5\" by adding user averages to.\n            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_movies_ratings.extend([test_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n        #     print(top_sim_movies_ratings, end=\" : -- \")\n\n            #-----------------prepare the row to be stores in a file-----------------#\n            row = list()\n            row.append(user)\n            row.append(movie)\n            # Now add the other features to this data...\n            row.append(test_averages['global']) # first feature\n            # next 5 features are similar_users \"movie\" ratings\n            row.extend(top_sim_users_ratings)\n            # next 5 features are \"user\" ratings for similar_movies\n            row.extend(top_sim_movies_ratings)\n            # Avg_user rating\n            row.append(test_averages['user'][user])\n            # Avg_movie rating\n            row.append(test_averages['movie'][movie])\n\n            # finalley, The actual Rating of this user-movie pair...\n            row.append(rating)\n            count = count + 1\n            final_test_data = final_test_data.append([row])\n#             print(count)\n\n           \n        \n#             if (count)%10000 == 0:\n#                 # print(','.join(map(str, row)))\n#                 print(\"Done for {} rows----- {}\".format(count, datetime.now()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_data.columns=['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n            'smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_data['mf_svd']=test_pred_mf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare Test data\nx_test = final_test_data.drop(['user','movie','rating'], axis=1)\ny_test = final_test_data['rating']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    \n#######################################\n# get the test data predictions and compute rmse and mape\n# print('Evaluating Test data')\ny_test_pred = xgb_model.predict(x_test) \n# rmse_test, mape_test = get_error_metrics(y_true=y_test.values, y_pred=y_test_pred)\n# store them in our test results dictionary.\n# test_results = {'rmse': rmse_test,\n#                     'mape' : mape_test,\n#                     'predictions':y_test_pred}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = [2,5,1,4]\narr = []\nfor i in range(len(y_test_pred)):\n    arr.append(i+1)\ndicti = {}\nfor i in range(len(arr)):\n    dicti[i+1] = y_test_pred[i]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic = sorted(dicti.items(),key = lambda x:x[1],reverse = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nans = []\ndata = pd.DataFrame()\nfor i in range(len(dic)):\n    ans.append(dic[i][0])\ndata[\"movieId\"] = ans","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv(\"Ordered_Movie.csv\",index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}